
# 당근마켓 채팅 시스템 아키텍처 

---


### Agenda

- 아키텍쳐 현대화
- 당근마켓 채팅 시스템의 현대화
- 데이터 분석과 모니터링


<br />

## 아키텍처의 현대화

---


### 기술의 변화

- 백엔드, Iot 애플리케이션, AI/ML , 워크로드, 배치 처리, PaaS 솔루션, 마이크로서비스 백엔드
- 새로운 아키텍처 패턴, 운영 모델 및 소프트웨어 전달

### 현대 아키텍처의 특징

- 느슨하게 결합된 서비스로 설계
- 경량화된 컨테이너 혹은 서버리스 함수로 패키징
- 상태 비저장(Stateless) 서비스와 상태 저장(Stateful) 서비스를 분리하여 설계
- 탄력적이며 회복력 있는 셀프-서비스 인프라스트럭처에 배포
- 서버 및 운영체제 종속성에서 격리

### 현대화를 위한 세가지 경로

- 관리형 컨테이너 서비스로 플랫폼 변경
- 서버리스 아키텍처에서 새롭고 안전한 앱 빌드
- 최신 Dev+Ops / 클라우드 네이티브 모델로 전환

### 혁신적 기술 관리와 새로운 기능 구축의 균형 유지

- 혁신 속도의 가속화
- 데이터를 활용 극대화
- 새로운 온라인 고객 경험 구축

### 애플리케이션 빌드 및 운영 방식 현대화

- 모듈화된 아키텍처 패턴
- 서버리스 운영 모델
- 애자일 개발 프로세스




<br /><br />

## 당근마켓의 채팅 시스템 모더나이제이션

---

### 당근마켓 기능

- 중고거래 송금
- 계좌번호 없이, 채팅창에서 바로 송금
- 생활편의 서비스 결제
- 선물하기, 로컬 커서므, 제휴 서비스도 간편 결제


<br />

![1z](https://user-images.githubusercontent.com/41246605/212835217-77bbb2b9-be6d-466b-96d9-64cdebf544a3.png)

- EKS 상에서 수십, 수백 개의 애플리케이션을 운영하고 있음

<br />

### 모놀리식 서비스

- 장애가 한번 발생하면 전체 장애로 이어짐

### 변화하는 서비스의 형태

- AS-IS
    - 앱 사용자를 위한 서비스
    - 유저와 직결되는 기능에 초점
    - 한 서버에서 모든 기능을 구현
    - 신규 기능은 모놀리팃 서비스에서 함수 형태로 구현
    - 규모가 커지며 길어지는 배포 주기
- TO-BE
    - 앱 사용자를 위한 서비스
    - 사내 개발자를 위한 서비스
    - 개발자를 위한 다양한 기능을 제공
    - API를 호출하는 형태로 지원
    - 경량화된 서비스 구성

<br />

### 마이크로서비스의 도입

- 기존에는 Main DB 의 60% 가 채팅 데이터
- 실제로 DB 가 가진 로우데이터만큼 Index 가 용량을 차지하고 있었음
- 전체 채팅 데이터 50% 가 Indexing 을 위해 할당되었음

- PostgreSQL 을 사용하면 Vacuum
    - 채팅을 위한 테이블에 Vacuum 이 일어나면 전체 DB에 많은 영향을 끼침
    - 이로 인해 응답시간이 저하

- 가장 많은 사용량을 가진 채팅 데이터를 Main DB에 둘 수 없다고 판단
- 이를 분리하기 위해 채팅 API 까지 전부 분리함

![2z](https://user-images.githubusercontent.com/41246605/212835272-e2ecfdda-8905-410f-a405-b504af0fa365.png)


- 기존 API 기능을 그대로 구현하고, LB (LoadBalancer) 단위에서 스위칭하는 프로젝트
- 데이터 모델링을 처음부터 효율적으로 진행
- 모든 채팅 데이터를 신규 데이터베이스로 마이그레이션 하는 작업까지 완료

<br />

![3z](https://user-images.githubusercontent.com/41246605/212835277-07ddbbd8-cb3e-4e1a-8aed-56b57633645e.png)


### Database Research 진행

- Managed Service 일 것
- 최대한 운영에 대한 시간을 아껴야 함
- 데이터 용량 확장에 용이할 것

### 가장 어려운 점

- 서비스가 커질수록 DB 운영에 많은 시간을 쏟고 있다는 점
- 최대한 운영시간을 줄이기 위해 Managed Service 가 지원되는 DB를 찾음
- 서비스가 성장하는 규모를 봤을 때 테라 페타 규모의 데이터 확장에도 견딜 수 있는 구조를 선택

### DynamoDB API

- 고가용성을 보장
- AWS에서 운영하는 안정성
- On-demand 모드로 사용하면 요청에 따라 Auto scaling 지원
- 성능은 수ms 정도로 DB 요청을 보장

### DynamoDB 를 사용하면서 어려운 점

- 일반적인 SLQ을 사용하지 못함
- 데이터를 가져오기 위해선 Query 와 Scan 으로 가져와야 함
- Query 는 인덱스를 건 item 만 가져올 수 있음
- Scan 으로 filter 를 걸 수 있음
- 다만, 실제 데이터를 전부 읽으면서 필터링해서 가져오기 때문에 비용 문제가 생길 수 있음
    - 실 서비스에서는 사용하면 안됨

- 인덱스를 잘 두어야 하기 때문에 설계에 대해서 고민이 많이 필요함
- Full scan 으로 전체 데이터에서 필터링하고 싶은 경우 DynamoDB 기능으로는 거의 불가능함

- 현재는 PartiQL 이라고 사용할 수 있기는 함
- 데이터를 가져올 때는 페이징을 기본적으로 구현해야 함
- Query 와 Scan 이라는 API 만을 사용해야 함
    - Query 는 미리 정한 인덱스를 통해 데이터를 가져오고
    - Scan 은 DynamoDB Engine 에서 데이터를 로드하고 필터하는 기능만을 제공
    - 실제로는 Query 만을 써야한다고 생각하면 좋을 것
    - 편하다고 처음에 Scan 만 사용해서 서비스를 구현한다면 비용관련해서 추후에 고생할 수 있음
- 만약 DynamoDB 에서 Full scan 을 하고 싶은 경우에는 어떻게 해야할까?
    - 약 100만 개 이상 DynamoDB 에 item 이 존재한다면 DynamoDB 에서 기본적으로 지원하는 기능으로는 사용하기 어려울 것

### Solution

- DynamoDB 를 사용한다면 별도의 분석을 위한 데이터 파이프라인을 구축해야 함

## 인덱스 설계

---

- 채팅방 하나가 Partition 하나라고 생각
- Sort key 는 Message 의 ID로 사용하고, Ordering 이 가능하면 손쉽게 최신 순으로 메세지를 정렬시킬 수 있음
- 일반적으로 하나의 채팅방에 동시에 접근할 수 있는 유저수도 많아도 1,000명 정도 이기 때문에, Hot partition issues 를 일으키는 쓰로틀링까지 도달하기 어렵습니다.
- 큰 문제 없이 운영이 가능한 설계

## API Server 설계

---

- Golang 으로 기존에 존재하는 모든 API 를 재구현
- 기존 서버에 강결합된 API 는 Internal API 로 재구현
- 기존 로직을 Internal API 통신으로 연동
- 작은 Util 함수까지도 테스트 케이스를 작성
- 성공/실패에 대한 대표적인 케이스들에 대해서 테스트 코드를 작성
- gRPC, WebSocket, REST API 수준의 테스트도 코드로 작성했습니다.
- 현재까지 약 1,250 개의 테스트가 Pull Request 시에 돌아가고 있습니다.
- 이를 통과하지 못하면 배포조차 못하게 하고 있습니다.

### WebSocket 을 통한 실시간 메시징 시스템을 도입하는 것

- 기존에는 FCM 에 의존하고 있어, Push 메시지가 밀리면 유저가 이미 접속하더라도 채팅 메시지를 받지 못하고 있었음
    - REST API 를 통해 메시지를 폴링하는 구조였음
- 이를 개션하기 위해 WebSocket 이 연결된 유저는 FCM 의 상태와 무관하게 이벤트를 받아서 처리할 수 있도록 하였습니다.

![4z](https://user-images.githubusercontent.com/41246605/212835285-373bc6ea-3030-4c89-8450-450bc0d093f5.png)


- 유저가 접속하면 각 서버에 붙어있음
- 유저간 메세지를 주고 받기 위해서는 다른 서버에 있는 유저에게 메세지를 전달해야 합니다.
- 이 때 gRPC 로 서버 간 Message 를 주고 받아 정상적으로 메세지를 전달하도록 되어 있습니다.


![5z](https://user-images.githubusercontent.com/41246605/212835290-489217f1-7dfa-48dd-a017-74cc64364341.png)


- 또한 Redis Cluster 를 특정한 용도로 사용하고 있습니다.
- Redis Cluster 를 사용하는 이유는 Session 을 관리하기 위함입니다.
- WebSocket 으로 접속한 유저가 어느 서버에 붙어있는지 관리하고 있습니다.
- Scale out을 쉽게 하기 위해 Cluster mode 로 사용하고 있습니다.
- 각 서버는 Connection 만을 맺고 있고, 유저의 세션은 Redis, 데이터는 DB에서 관리하고 있어서 크게 서버에 붙어있는 User 의 State를 관리하는 것이 요구되지 않았습니다.


### 데이터 분석 방식

- 기존의 RDBMS에 의존한 분석 방식을 더이상 사용할 수 없게 됨
- 채팅은 별도의 Data pipeline 을 구축하였습니다.

### 데이터 분석 Pipeline

- DynamoDB Stream
    - DynamoDB 에 있는 데이터를 실시간으로 처리하기 위한 DynamoDB Stream
- Lambda
    - Stream 에 있는 데이터를 원하는 곳에 적재하기 위한 Lambda
- Firehose
    - 이벤트 버퍼를 S3 에 업로드하는 Firehose
- S3
    - Data warehouse 의 storage 역할을 하는 S3
- Athena
    - 데이터 가시화를 지원하는 Athena

![6z](https://user-images.githubusercontent.com/41246605/212835314-45ee3fdd-2948-4f82-bad3-e99a5dbf4dac.png)


- API Server 및 DynamoDB 에서 발생한 데이터를 Superset 과 같은 BI 도구에서 시각화하는 과정
- Amazon DynamoDB Stream 의 특징
    - 시간 순서에 따라 Stream 에 DynamoDB 에서 발생한 CUD 이벤트를 밀어 넣어줍니다.
    - 이러한 변경내역을 Change Data Capture 라고 부름
    - 이 정보를 최대 24시간 동안 로그에 저장하고 Stream 을 읽어서 별도로 저장하거나 변경하거나 분석할 수 있습니다.
    - 거의 실시간으로 이벤트를 받아서 처리할 수 있다.
    - 어플리케이션 레벨에서 엑세스해서 원하는 처리를 할 수 있습니다.
- DynamoDB Stream Record 를 AWS Lambda 로 받아서 처리합니다.
    - 새로운 DynamoDB Stream Record 가 감지될 때마다 폴링하는 구조로 설계되어 있습니다.
    - Lambda 함수를 동기식으로 호출하고 있습니다.
    - 하지만 DynamoItem 형식이라 바로 처리하기 애매한 점이 있습니다.
        - DynamoDB SDK 를 통해 CRUD를 구현해보면 경험할 수 있는데,
        - String Value 가 S라는 key로 감싸진 map으로 하나의 attribute 가 구현되어 있습니다.
        - 이런 불필요한 Struct 를 풀어서 Key-Value 형태로만 저장하는 용도로 Lambda 함수를 구현해두었습니다.
        - Lambda 가 S3 로 바로 업로드하기에는 Stream Records 의 사이즈가 그렇게 크지 않습니다.
        - 그렇기 때문에 Firehose 에 Record 를 밀어넣어서 S3에 올라가는 파일의 사이즈를 좀더 크게 하고 안정적으로 서빙 가능하도록 하고 있습니다.

- Stream Records 로 받는 원본 형태의 데이터와 저장하는 데이터를 표현한 내용


![7z](https://user-images.githubusercontent.com/41246605/212835324-159bd2a6-2e3b-4b41-ab4c-dac48631b5ec.png)


- 분석할 때 사용하지 않는 필드들은 제거하도록 하고, New Image 기준으로 Key/value 만 저장하도록 하고 있습니다.
- 이미 DynamoDB 에 Item 이 들어갈 때 Item 의 생성시간 및 업데이트 시간이 들어가 있기 때문에 new Item 만 저장하도록 처리하고 있습니다.
- OLAP 관점에서 Nested structure 인 json 보다 최소한된 구조로만 되어있는 json 이 더 빠르게 분석할 수 있는 데이터라는 장점이 있습니다.
- 또한 당연히 불필요한 값이 존재하지 않으니 파일 사이즈도 줄어듭니다.


### Amazon Kinesis Data Firehose

- 데이터를 Amazon S3로 전송하기 전에 수신되는 데이터를 Apache Parquet 및 Apache ORC와 같은 Columnar 기반 형식으로 변환하도록 전송 스트림 구성이 가능함
- 서버리스형 스트림 서비스
- S3로 저장 지원
- GZIP, ZIP, SNAPPY 압축 형식 지원
- 날짜 및 시간으로 Partitioning 하여 S3에 저장 가능

### Kinesis Data Firehose 데이터 Flow

- Amazon S3 에 데이터를 전송하기 전에 수신되는 데이터를 모아서 Parquet, ORC 와 같은 Columnar 기반 형식으로 변환이 가능합니다.
- Kinesis 는 샤드의 개수 관리를 해야하는 것에 비해 Firehose 는 서버리스형 스트림 서비스입니다.
- S3로 저장을 지원할 뿐만 아니라, Datadog, Amazon Open Search Service, HTTP Endpoint 등과 같이 자원하는 서비스 엔드포인트에 Data를 보낼 수 있습니다.
- S3에 저장할 때 GZIP, ZIP, SNAPPY와 같은 압축형식을 지원하기 때문에, 저장 공간을 절약할 수 있습니다.
- 또한 동적으로 날짜 및 시간으로 파티셔팅하여 S3에 저장도 가능합니다.

### Firehose 의 정보로, S3 Bucket 에 Prefix를 시간단위까지 파티셔닝한 설정화면

![8z](https://user-images.githubusercontent.com/41246605/212835341-a4bed7ff-7527-45f5-ae3c-0ed5a1c0c053.png)


- 년, 월, 일, 시, 분 단위까지 설정 가능
- 시간단위로 파티셔닝을 하는 이유는 나중에 S3 Object 를 읽어서 Athena 와 같은 쿼리 엔진으로 분석할 때를 대비하기 위함입니다.
- 원하는 범위의 데이터만 읽을 수 있도록 지원하기 때문에 상당히 비용 효율적이라는 장점이 있습니다.
- 또한 설정만으로 알아서 GZIP 으로 압축해서 저장하기 때문에 저장공간도 아낄 수 있습니다.
- 언제까지 Records 를 받아서 Buffer 가 128MB까지 될 때를 기다릴 수 없으니 60초마다 새로 Buffer를 받을 수 있도록 설정하였습니다.


### 데이터 파이프라인 배포 방법

- 구성요소가 많지만 Serverless Framework 를 통해 배포과정을 간소화해서 관리하고 있습니다.

![9z](https://user-images.githubusercontent.com/41246605/212835349-db32388c-91b0-4b64-9787-108f597d80bf.png)


- 먼저 DynamoDB 설정에서 Stream 기능을 켜놓습니다.
- 그리고 Firehose 를 생성합니다.
- Serverless framework 에서 DynamoDB Stream ARN 과 Firehose ARN 값을 넣어서 스트림 하나씩 배포합니다.
- 미리 템플리팅 해놓은 Serverless Framework 설정파일이기 때문에 다른 팀에서도 DynamoDB를 분석하는 Log pipeline 을 생성하고 싶을 때 application 이름만 바꾸고, DynamoDB Stream ARN , Firehose ARN 값을 넣어서 손쉽고빠르게 배포할 수 있습니다.

당근마켓은 DynamoDB 를 사용하는 대부분의 서비스들은 이와 같이 데이퍼 파이프 라인을 운영하고 있습니다.


### Amazon Athena

- S3에 떨어진 데이터는 Athena를 활용해서 빠르게 검색하고 분석할 수 있습니다.
- Athena는 Apache Presto 기반의 서버리스형 데이터 조회 서비스입니다.
- 다양한 형식의 포맷을 지원하는데, CSV, JSON, ORC, Avro, Parquet 과 같은 데이터 포맷을 지원합니다.
- 또한 파티셔닝된 데이터조회를 지원하기 때문에 불필요하게 많은 데이터를 읽는 프로세스는 제거할 수 있습니다.

## AWS Glue

> 기존 PostgreSQL 데이터베이스에 데이터가 있기 때문에, 채팅 데이터가 DynamoDB 로 별도 분리되었다고 해도 통계를 위해 데이터를 Join 해서 봐야 하는 경우가 생김

이때 AWS Glue 를 통해 필요한 데이터를 Dump 하여 S3에 데이터를 로드하고 있습니다.
>

- 완전 관리형 ETL (추출, 변환 및 로드) 서비스
- Athena 에서 쿼리할 테이블을 관리
- Glue Crawler 로 PostgreSQL DB의 테이블을 Describe 해서 스키마를 읽을 수 있음
- S3에 있는 데이터를 크롤링해서 파일타입과 스키마를 읽을 수 있음
- Job을 생성하고 싶을 때는 Pyspark를 사용한 script 를 통해 ETL 진행
- 자체적인 Scheduler 로 매일 ETL 을 Glue에서 설정만으로 Trigger 할 수 있음
- 데이터 카탈로그를 저장할 수있는 저장소로도 활용 가능
- PostgreSQL 에 있는 데이터를 Glue JOB을 통해 S3로 Dump 하도록 하는 스크립트를 돌리고 있습니다.
- 이렇게 나온 데이터를 분석하기 위해 직접 Schema 를 작성해도 좋지만 Glue 에 있는 Crawler 로 다시 Dump 된 S3데이터를 읽으면 손쉽게 카탈로그에 등록할 수 있습니다.

## Dump 데이터 S3 데이터 Athena 에서 조인

> 이렇게 S3에 Dump 된 데이터와 DynamoDB Stream 으로 받아서 S3에 떨어진 데이터를 Athena 에서 조인하여 우너하는 데이터를 분석할 수 있습니다.
>

### Pyspark 로 작성된 Glue Job script 예시


![10z](https://user-images.githubusercontent.com/41246605/212835361-a199b73e-2bd2-436b-9e0b-12a5bcd4457b.png)


- Glue Job을 통해 PostgreSQL 에 있는 Table 을 S3로 Dump
- Glue Crawler 로 Glue Table 생성
- Athena 를 통해 DynamoDB Event 와 PostgreSQL Table 을 조인하여 원하는 데이터 분석
- Dump할 Table list 를 받아서 Parquet 형식으로 S3에 저장하는 스크립트입니다.
- RDB 에서 덤프가 필요한 경우 이처럼 Glue Job Script 를 작성하여 S3로 데이터를 보내주고 있습니다.
- 만약 이 과정을 생략하고 싶다면 Athena Federated Query 로 Athena가 Lambda를 통해 직접적으로 RDB Connection 을 맺고 데이터를 조회할 수도 있습니다.


![11z](https://user-images.githubusercontent.com/41246605/212835403-006920dd-cadc-46d0-a476-b6e2b6448b43.png)


- 분석 통계를 뽑는 Workflow 는 AWS Step Functions 를 사용
- S3 에 있는 데이터를 Athena를 통해 쿼리하고 결과를 S3에 저장
- Eventbridge Scheduler 를 통해 매일 자정에 Trigger 됨

> Athena로 매일 사용내역에 대해서 통계를 출력하고 이를 집계용 DB에 넣어줘야 한다.


## AWS Step Functions

---

- 통계를 위한 워크플로우 관리를 하고 있다.
- 일반적으로 Apache Airflow 로 서비스를 운영하며 사용하고 있다.
- 다만, 소규모의 팀에서 운영을 최소화하기 위해서는 서버리스 형태의 워크플로우를 도입해야 한다.

### Step functions

![12z](https://user-images.githubusercontent.com/41246605/212835388-a3b2c135-fac7-4485-a87d-f53ea967525f.png)


- Scheduler 로 매일 자정에 Trigger 되고, Athena 로 쿼리한 결과를 S3에 CSV 로 내려주는 역할을 하고 있다.
- 이 또한 Serverless Framework 로 관리하고 있고, 쿼리가 추가될 때마다 이벤트 트리거만 하나씩 추가하는 형태로 관리하고 있습니다.


# 채팅 데이터를 다른 서비스에서 활용하기

---


![13z](https://user-images.githubusercontent.com/41246605/212835412-85f16c9f-637a-4039-aff0-a0c9452d4f24.png)

- 채팅방에 생성되는 것과 같은 다양한 이벤트들에 대해서 다른 서비스가 데이터를 처리하는 방법이 필요합니다.
- 이를 위해 Kafka 를 통해 Pub/sub 을 하는 구조를 가져가고 있습니다.
- 그러나 kafka 로 데이터를 보내는 것을 보장해야하는 상황에 직면
- 이를 해결하기 위해 Fluent Bit 를 활용한 Buffer 를 두기 시작했다.
- 채팅서버는 Fluent Bit 에 공유할 이벤트를 보내줍니다.
- Fluent Bit 는 안정적으로 이벤트를 Kafka, S3, Firehose 와 같은 Output 으로 이벤트를 안정적으로 전달해줍니다.
- kafka 장애 시에는 Fluent Bit 가 로컬디스크에 데이터를 쓰다가 kafka 가 복구되면 장애시점부터 다시 이벤트를 퍼블리시 해주는 것과 같이 이벤트가 유실되는 것을 방지해주고 있습니다.


![14z](https://user-images.githubusercontent.com/41246605/212835422-2fc012a4-a958-455e-bbf8-76a30c1197d0.png)


### FluentBit

![15z](https://user-images.githubusercontent.com/41246605/212835434-b5be5591-1e16-45d3-b830-af9250707dfa.png)


- FluentBit 은 초경량으로 현재 프로덕션에서 0.1 Core 도 사용하지 않고 있습니다.
- 성능이 좋아서 거의 컴퓨팅 자원을 사용하지 않는 애플리케이션입니다.
- 다양한 Output 을 둘 수 있어서 대부분의 케이스의 이벤트는 받아서 처리할 수 있습니다.
- Filter / Parser 를 지원해서 원하는 데이터만 그리고 필요한 데이터만 보고 저장할 수 있도록 지원합니다.
- 아래는 Fluent Bit Client 를 생성하고 이벤트를 보내는 코드로, 어떠한 언어로도 아주 간단하게 이벤트를 처리할 수 있습니다.

> 각 서비스는 Kafka 에 Publish 된 Event 에 대해서 Consumer 를 구현하여 소비하고 있습니다.
서비스 간 느슨하게 연결된 형태로 운영하고 있습니다.



![16z](https://user-images.githubusercontent.com/41246605/212835444-a6ba02f7-4147-4cd1-b142-24bbac1b11ce.png)


> 지금의 문제점은 무엇일까?
2달 혹은 3달 후에 더 운영이 편한 방식은 어떤 것이 있을까?





# Reference

---

- [https://www.youtube.com/watch?v=lCxgddyxDyg](https://www.youtube.com/watch?v=lCxgddyxDyg)


